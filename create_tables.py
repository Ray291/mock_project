# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kqipnzkq1avyvPZMVkxBMta956pezOOI
"""

!apt-get install openjdk-8-jdk-headless -qq > /dev/null
!wget -q https://dlcdn.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz
!tar xf spark-3.2.1-bin-hadoop3.2.tgz
!pip install -q findspark

import os
os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-8-openjdk-amd64"
os.environ["SPARK_HOME"] = "/content/spark-3.2.1-bin-hadoop3.2"

import findspark
findspark.init()
from pyspark.sql import SparkSession
spark = SparkSession.builder.master("local[*]").appName("firstSpark").getOrCreate()

from functools import reduce
from pyspark import SparkContext
from pyspark.sql import SparkSession, Window, Row
from pyspark.sql.functions import *
from pyspark.sql.types import *

import pandas as pd
import numpy as np

"""#Load data

##Promotion
"""

campaign = spark.read.option("header","true").csv("/content/drive/MyDrive/2022/project/data/source/configs/campaign.csv")
campaign = campaign.select(split(col("campaignID\tcampaignType\texpireDate\texpireTime"),"\t").getItem(0).alias("campaignID"),
                           split(col("campaignID\tcampaignType\texpireDate\texpireTime"),"\t").getItem(1).alias("campaignType"),
                           split(col("campaignID\tcampaignType\texpireDate\texpireTime"),"\t").getItem(2).alias("expireDate"),
                           split(col("campaignID\tcampaignType\texpireDate\texpireTime"),"\t").getItem(3).alias("expireTime")) \
                            .drop("campaignID\tcampaignType\texpireDate\texpireTime").cache()
campaign.show(5)

promotion = spark.read.option("header","true").csv("/content/drive/MyDrive/2022/project/data/source/promotions/2021-11-01/part-00000-802e6ae2-b27d-463b-a5c0-5b2d91ad831f-c000.csv")
promotion = promotion.select(split(col("userid\tvoucherCode\tstatus\tcampaignID\ttime"),"\t").getItem(0).alias("userid"),
                           split(col("userid\tvoucherCode\tstatus\tcampaignID\ttime"),"\t").getItem(1).alias("voucherCode"),
                           split(col("userid\tvoucherCode\tstatus\tcampaignID\ttime"),"\t").getItem(2).alias("status"),
                           split(col("userid\tvoucherCode\tstatus\tcampaignID\ttime"),"\t").getItem(3).alias("campaignID"),
                           split(col("userid\tvoucherCode\tstatus\tcampaignID\ttime"),"\t").getItem(4).alias("time")) \
                            .drop("userid\tvoucherCode\tstatus\tcampaignID\ttime").cache()
promotion.show(5)

"""##Mapping"""

mapping_appid = spark.read.option("header","true").csv("/content/drive/MyDrive/2022/project/data/source/mapping/appid.csv")
mapping_appid = mapping_appid.select(split(col("appid appname"),"  ").getItem(0).alias("appid"),
                           split(col("appid appname"),"  ").getItem(1).alias("appname"),
                          ) \
                            .drop("appid appname").cache()
mapping_appid.show()

mapping_gender = spark.read.option("header","true").csv("/content/drive/MyDrive/2022/project/data/source/mapping/gender.csv")
mapping_gender = mapping_gender.select(split(col("gender\tgenderName"),"\t").getItem(0).alias("gender"),
                           split(col("gender\tgenderName"),"\t").getItem(1).alias("genderName"),
                          ) \
                            .drop("gender\tgenderName").cache()
mapping_gender.show(5)

map_profile = spark.read.option("header","true").csv("/content/drive/MyDrive/2022/project/data/source/mapping/profileLevel.csv")
map_profile = map_profile.select(split(col("profileLevel\tprofileLevelName"),"\t").getItem(0).alias("profileLevel"),
                           split(col("profileLevel\tprofileLevelName"),"\t").getItem(1).alias("profileLevelName"),
                          ) \
                            .drop("profileLevel\tprofileLevelName").cache()
map_profile.show(5)

map_transtype = spark.read.option("header","true").csv("/content/drive/MyDrive/2022/project/data/source/mapping/transtype.csv")
map_transtype = map_transtype.select(split(col("transtype\ttranstypename"),"\t").getItem(0).alias("transtype"),
                           split(col("transtype\ttranstypename"),"\t").getItem(1).alias("transtypename"),
                          ) \
                            .drop("transtype\ttranstypename").cache()
map_transtype.show(5)

"""##Transactions"""

transaction = spark.read.option("header","true").csv("/content/drive/MyDrive/2022/project/data/source/transactions/2021-11-01/part-00000-8f0661ad-96d1-41c9-9b42-0d887254a35f-c000.csv")
transaction = transaction.select(split(col("transId\ttransStatus\tuserId\ttransactionTime\tappId\ttransType\tamount\tpmcId"),"\t").getItem(0).alias("transId"),
                           split(col("transId\ttransStatus\tuserId\ttransactionTime\tappId\ttransType\tamount\tpmcId"),"\t").getItem(1).alias("transStatus"),
                           split(col("transId\ttransStatus\tuserId\ttransactionTime\tappId\ttransType\tamount\tpmcId"),"\t").getItem(2).alias("userId"),
                           split(col("transId\ttransStatus\tuserId\ttransactionTime\tappId\ttransType\tamount\tpmcId"),"\t").getItem(3).alias("transactionTime"),
                           split(col("transId\ttransStatus\tuserId\ttransactionTime\tappId\ttransType\tamount\tpmcId"),"\t").getItem(4).alias("appId"),
                           split(col("transId\ttransStatus\tuserId\ttransactionTime\tappId\ttransType\tamount\tpmcId"),"\t").getItem(5).alias("transType"),
                           split(col("transId\ttransStatus\tuserId\ttransactionTime\tappId\ttransType\tamount\tpmcId"),"\t").getItem(6).alias("amount"),
                           split(col("transId\ttransStatus\tuserId\ttransactionTime\tappId\ttransType\tamount\tpmcId"),"\t").getItem(7).alias("pmcId")) \
                            .drop("transId\ttransStatus\tuserId\ttransactionTime\tappId\ttransType\tamount\tpmcId").cache()
transaction.show(5)

"""##Users"""

users = spark.read.option("header","true").csv("/content/drive/MyDrive/2022/project/data/source/users/2021-11-01/part-00000-90950e0e-e0ae-4b04-a8ba-e2e6d8420f9e-c000.csv")
users = users.select(split(col("userid\tbirthdate\tprofileLevel\tgender\tupdatedTime"),"\t").getItem(0).alias("userid"),
                           split(col("userid\tbirthdate\tprofileLevel\tgender\tupdatedTime"),"\t").getItem(1).alias("birthdate"),
                           split(col("userid\tbirthdate\tprofileLevel\tgender\tupdatedTime"),"\t").getItem(2).alias("profileLevel"),
                           split(col("userid\tbirthdate\tprofileLevel\tgender\tupdatedTime"),"\t").getItem(3).alias("gender"),
                           split(col("userid\tbirthdate\tprofileLevel\tgender\tupdatedTime"),"\t").getItem(4).alias("updatedTime")) \
                            .drop("transId\ttransStatus\tuserId\ttransactionTime\tappId\ttransType\tamount\tpmcId").cache()
users.show(5)

"""#Update to latest data

###Latest users
"""

winSpec_user = Window.partitionBy("userid")
latest_users = users.withColumn("latest_update", max("updatedTime").over(winSpec_user))
latest_users = latest_users.filter("latest_update == updatedTime")
latest_users.show(5)
print(latest_users.count())

"""###Earliest and latest transactions """

winSpec_trans = Window.partitionBy("userid")
updated_transaction = transaction.withColumn("latest_active", max("transactionTime").over(winSpec_trans))
updated_transaction = updated_transaction.withColumn("earliest_active", min("transactionTime").over(winSpec_trans))
updated_transaction = updated_transaction.withColumn("latest_transaction", 
                                                     when(updated_transaction.transStatus== 1,
                                                          max("transactionTime").over(winSpec_trans)).otherwise("null"))
updated_transaction = updated_transaction.withColumn("earliest_transaction", 
                                                     when(updated_transaction.transStatus== 1,
                                                          min("transactionTime").over(winSpec_trans)).otherwise("null"))
updated_transaction.show(5)
print(updated_transaction.count())

updated_transaction.filter(updated_transaction.appId.isNull()).show()

"""#Create tables"""

demographic = latest_users
demographic = demographic.join(mapping_gender,"gender","leftouter").join(map_profile,"profileLevel","leftouter").drop("profileLevel","gender")
demographic.show(5)
demographic.summary().show()

demographic.select(demographic.genderName).distinct().show()

activity = updated_transaction.select("userId","appId","transType","pmcId","latest_active","earliest_active","latest_transaction","earliest_transaction")
activity = activity.join(mapping_appid,activity.appId==mapping_appid.appid,"fullouter") \
                    .join(map_transtype,activity.transType==map_transtype.transtype,"fullouter") \
                    .drop(mapping_appid.appid).drop(map_transtype.transtype)

activity.show()
print(activity.count())

activity.select(activity.appname).distinct().show()

promotions = promotion.join(campaign,"campaignID","fullouter")
promotions.show(5)